# DL CookBook Progress

[▓▓▓░░░░░░░░░░░░░░] 10.86% (20/184)

## Neural Network Architectures

<details>
  <summary>Basic Architectures (4/4)</summary>

  - [x] MLP
  - [x] CNN
  - [x] ResNet
  - [x] DenseNet

</details>

<details>
  <summary>Recurrent Networks (5/5)</summary>

  - [x] Vanilla RNN
  - [x] Bidirectional RNN
  - [x] GRU
  - [x] LSTM
  - [x] Memory Networks

</details>

<details>
  <summary>Auto-Encoders (4/4)</summary>

  - [x] Sparse
  - [x] Variational
  - [x] Contractive
  - [x] VQ-VAE

</details>

<details>
  <summary>Transformers (7/11)</summary>

  - [x] Vanilla
  - [x] Linear
  - [x] Sparse
  - [x] Gaussian
  - [x] Differential
  - [x] Universal
  - [x] Negative-Weights
  - [ ] FlashAttention (v1/v2/v3)
  - [ ] Transformers^2
  - [ ] Titans
  - [ ] Atlas

</details>

<details>
  <summary>Diffusion Models (0/4)</summary>

  - [ ] DDPM
  - [ ] DDIM
  - [ ] Latent Diffusion
  - [ ] Large Language Diffusion

</details>

<details>
  <summary>State Space Models (0/3)</summary>

  - [ ] Mamba
  - [ ] S4
  - [ ] H3

</details>

<details>
  <summary>Physics-Informed Neural Networks (0/5)</summary>

  - [ ] Neural ODE
  - [ ] Fourier Neural Operator
  - [ ] Deep Operator Networks
  - [ ] Hamiltonian Neural Networks
  - [ ] Lagrangian Neural Networks

</details>

<details>
  <summary>Graph Neural Networks (0/5)</summary>

  - [ ] Graph Convolutional Networks (GCN)
  - [ ] Graph Attention Networks (GAT)
  - [ ] Message Passing Neural Networks
  - [ ] Graph Transformers
  - [ ] Graph Normalizing Flows

</details>

<details>
  <summary>Generative Adversarial Networks (0/5)</summary>

  - [ ] DCGAN
  - [ ] WGAN
  - [ ] CycleGAN
  - [ ] StyleGAN
  - [ ] BigGAN

</details>

<details>
  <summary>Energy-Based Models (0/4)</summary>

  - [ ] Restricted Boltzmann Machines
  - [ ] Deep Belief Networks
  - [ ] Deep Energy Networks
  - [ ] Normalizing Flows

</details>

<details>
  <summary>Hyperbolic Networks (0/5)</summary>

  - [ ] H-Attention Network
  - [ ] H-Graph Network
  - [ ] H-Normalizing Flows
  - [ ] H-VAE
  - [ ] Mixed Geometry Networks

</details>

<details>
  <summary>Specialized Architectures (0/8)</summary>

  - [ ] Kolmogorov-Arnold Networks
  - [ ] Mixture of Experts
  - [ ] Fuzzy Neural Networks
  - [ ] Jacobian Fields
  - [ ] Spiking Neural Networks
  - [ ] Free-Equivariance Neural Networks
  - [ ] Neural Causal Models
  - [ ] Large Concept Models

</details>

## Reinforcement Learning Algorithms

<details>
  <summary>Value-Based Methods (0/7)</summary>

  - [ ] Deep Q-Networks (DQN)
  - [ ] Double DQN
  - [ ] Dueling DQN
  - [ ] Rainbow DQN
  - [ ] Categorical 51-Atom DQN (C51)
  - [ ] Quantile Regression DQN (QR-DQN)
  - [ ] Implicit Quantile Networks (IQN)

</details>

<details>
  <summary>Policy Gradient Methods (0/8)</summary>

  - [ ] Asynchronous Advantage Actor-Critic (A3C)
  - [ ] Advantage Actor-Critic (A2C)
  - [ ] Proximal Policy Optimization (PPO)
  - [ ] Trust Region Policy Optimization (TRPO)
  - [ ] Deep Deterministic Policy Gradient (DDPG)
  - [ ] Twin Delayed DDPG (TD3)
  - [ ] Soft Actor-Critic (SAC)
  - [ ] Group Related Policy Optimization (GRPO)

</details>

<details>
  <summary>Model-Based Methods (0/6)</summary>

  - [ ] World Models
  - [ ] Imagination-Augmented Agents (I2A)
  - [ ] Model-Based RL with Model-Free Fine-Tuning (MBMF)
  - [ ] Model-Based Value Expansion (MVE)
  - [ ] Dreamer
  - [ ] PlaNet

</details>

<details>
  <summary>Multi-Agent RL (0/4)</summary>

  - [ ] Multi-Agent DDPG (MADDPG)
  - [ ] Counter-Factual Multi-Agent (COMA)
  - [ ] Multi-Agent PPO (MAPPO)
  - [ ] Multi-Agent SAC (MASAC)

</details>

<details>
  <summary>Exploration Strategies (0/4)</summary>

  - [ ] Hindsight Experience Replay (HER)
  - [ ] Random Network Distillation (RND)
  - [ ] Never Give Up (NGU)
  - [ ] Go-Explore

</details>

<details>
  <summary>Game-Playing and Planning (0/4)</summary>

  - [ ] AlphaZero
  - [ ] MuZero
  - [ ] AlphaGo
  - [ ] Monte Carlo Tree Search (MCTS)

</details>

<details>
  <summary>Offline RL (0/4)</summary>

  - [ ] Conservative Q-Learning (CQL)
  - [ ] Behavior Regularized Actor Critic (BRAC)
  - [ ] Implicit Q-Learning (IQL)
  - [ ] Decision Transformer

</details>

<details>
  <summary>Meta-RL (0/4)</summary>

  - [ ] RL^2
  - [ ] MAML for RL
  - [ ] PEARL
  - [ ] ProMP

</details>

<details>
  <summary>Hierarchical RL (0/4)</summary>

  - [ ] Option-Critic
  - [ ] Hierarchical Actor-Critic (HAC)
  - [ ] HIRO
  - [ ] FUN

</details>

## Optimization Algorithms

<details>
  <summary>First-Order Methods (0/14)</summary>

  - [ ] Stochastic Gradient Descent (SGD)
  - [ ] SGD with Momentum
  - [ ] SGD with Nesterov Momentum
  - [ ] AdaGrad
  - [ ] AdaDelta
  - [ ] RMSProp
  - [ ] Adam and Variants
  - [ ] Adam
  - [ ] AdamW
  - [ ] NAdam
  - [ ] RAdam
  - [ ] AdaMomentum
  - [ ] AdaBelief
  - [ ] AdaFactor

</details>

<details>
  <summary>Large-Scale/Distributed Training (0/5)</summary>

  - [ ] LARS (Layer-wise Adaptive Rate Scaling)
  - [ ] LAMB (Layer-wise Adaptive Moments for Batch training)
  - [ ] Shampoo
  - [ ] SOAP
  - [ ] FTRL (Follow The Regularized Leader)

</details>

<details>
  <summary>Recent Innovations (0/7)</summary>

  - [ ] Lion
  - [ ] Prodigy
  - [ ] Sophia
  - [ ] Muon
  - [ ] DeMo
  - [ ] Adan
  - [ ] Ranger

</details>

<details>
  <summary>Geometric Methods (0/3)</summary>

  - [ ] Reimann SGD
  - [ ] Natural Gradient Descent
  - [ ] Mirror Descent

</details>

<details>
  <summary>Adaptive Learning Rate Methods (0/4)</summary>

  - [ ] Cyclical Learning Rates
  - [ ] One Cycle Policy
  - [ ] Cosine Annealing
  - [ ] SGDR (Stochastic Gradient Descent with Restarts)

</details>

<details>
  <summary>Hybrid Methods (0/5)</summary>

  - [ ] AdaScale
  - [ ] NovoGrad
  - [ ] Apollo
  - [ ] MADGRAD
  - [ ] SAM (Sharpness-Aware Minimization)

</details>

<details>
  <summary>Specialized Optimizers (0/6)</summary>

  - [ ] Lookahead Optimizer
  - [ ] Rectified Adam
  - [ ] AGC (Adaptive Gradient Clipping)
  - [ ] LBFGS (Limited-memory BFGS)
  - [ ] AdaMax
  - [ ] AMSGrad

</details>

## Tokenization

<details>
  <summary>Tokenizing Techniques (0/7)</summary>

  - [ ] Byte Pair Encoding
  - [ ] Character-level tokenization
  - [ ] Character-aware tokenization via CNNs
  - [ ] Raw byte-level end-to-end learned tokenization
  - [ ] Byte Latent Transformers
  - [ ] MrT5 Token Deletion gates
  - [ ] EvaByte

</details>

## Distributed Training

<details>
  <summary>Distributed Training (0/14)</summary>
  
  - [ ] MegatronLM
  - [ ] GPipe
  - [ ] Alpa
  - [ ] Tenplex
  - [ ] DeepSeed
  - [ ] PipeDream
  - [ ] ZeRO
  - [ ] PyTorch DDP
  - [ ] Horovod
  - [ ] TensorFlow Distribution Strategy
  - [ ] Ray Train
  - [ ] FairScale
  - [ ] Colossal-AI
  - [ ] JAX pmap/pjit

</details>

<br>

# Architectures Excluded

- Neural Turing Machines
- Differentiable Neural Computers
- Memory-Augmented Neural Networks
- Beta Variational Auto-encoders
- Convolutional Auto-encoders
- Conditional Auto-encoders
- Vision Transformers
- Performer
- Reformer
- Longformer
- FNet
- Routing Transformers
- Perceiver/Perceiver IO
- SinkFormers