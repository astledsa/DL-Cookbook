---
title: "Gaussian Adaptive Transformers"
date: 2024-12-10
draft: false
references:
  - title: "Gaussian Adaptive Attention is all you need: Robust contexual representations across multiple modalitites"
    url: "https://arxiv.org/abs/2401.11143v3"  
---

As transformers became more and more popular, research into finding better and more efficient variants of the said architecture exploded, and various new modifications were made over the past few years. (Which makes writing an up-to-date book on deep learning that much troublesome!)